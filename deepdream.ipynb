{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6294c68-ccd8-42ea-9e57-d4486253a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is from:  https://blog.mlq.ai/deep-dream-with-tensorflow-2-0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888abb6c-9e19-43e2-94a1-2c1798e7be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c88fb0-314f-461a-adc8-fc87622e89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "names = ['mixed3', 'mixed5']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "deepdream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb009a-1849-4bf7-8706-d651c30b03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Image = tf.keras.preprocessing.image.load_img(r'starry.jpg', target_size=(225, 375))\n",
    "Sample_Image = np.array(Sample_Image)#/255.0\n",
    "Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)\n",
    "Sample_Image = tf.Variable(tf.keras.applications.inception_v3.preprocess_input(Sample_Image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf1caf-9a3b-4e29-b86c-fb5053a08cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(image, model):\n",
    "  # convert to batch format\n",
    "  img_batch = tf.expand_dims(image, axis=0)\n",
    "  # run the model\n",
    "  layer_activations = model(img_batch)\n",
    "\n",
    "  # create an empty array to accumulate the losses\n",
    "  losses = []\n",
    "  for act in layer_activations:\n",
    "    # calculate the mean of each activation\n",
    "    loss = tf.math.reduce_mean(act)\n",
    "    losses.append(loss)\n",
    "\n",
    "  # calcualte sum\n",
    "  return tf.reduce_sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872ddc2-6a05-4df9-8b35-b4a2bc8eedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def deepdream(model, image, step_size):\n",
    "    with tf.GradientTape() as tape:\n",
    "      tape.watch(image)\n",
    "      loss = calc_loss(image, model) \n",
    "\n",
    "    gradients = tape.gradient(loss, image)\n",
    "\n",
    "    gradients /= tf.math.reduce_std(gradients)  \n",
    "\n",
    "    image = image + gradients * step_size\n",
    "    image = tf.clip_by_value(image, -1, 1)\n",
    "\n",
    "    return loss, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976beddf-d63c-4eb6-a92b-2eb55fa2afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deep_dream_simple(model, image, steps=100, step_size=0.01):\n",
    "  #image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
    "\n",
    "  for step in range(steps):\n",
    "    loss, image = deepdream(model, image, step_size)\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "      plt.figure(figsize=(12,12))\n",
    "      plt.imshow(deprocess(image))\n",
    "      plt.show()\n",
    "      print (\"Step {}, loss {}\".format(step, loss))\n",
    "\n",
    "  plt.figure(figsize=(12,12))\n",
    "  plt.imshow(deprocess(image))\n",
    "  plt.show()\n",
    "\n",
    "  return deprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa7fd8b-3ef6-4986-9535-86a2acf50a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(image):\n",
    "  image = 255*(image + 1.0)/2.0\n",
    "  return tf.cast(image, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176551d-792f-4a5a-9b17-804a00cd9c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dream_img = run_deep_dream_simple(model=deepdream_model, image=Sample_Image, \n",
    "                                  steps=2000, step_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b13d5-6876-4e3e-b651-f9e3930bd4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba35923-b3d5-43d8-9419-cd5da80784f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e522722-c816-4469-9b6f-b5c4644f03aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
